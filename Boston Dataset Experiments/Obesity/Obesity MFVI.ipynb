{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 544, 'name': 'Estimation of Obesity Levels Based On Eating Habits and Physical Condition ', 'repository_url': 'https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition', 'data_url': 'https://archive.ics.uci.edu/static/public/544/data.csv', 'abstract': 'This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. ', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Regression', 'Clustering'], 'characteristics': ['Multivariate'], 'num_instances': 2111, 'num_features': 16, 'feature_types': ['Integer'], 'demographics': ['Gender', 'Age'], 'target_col': ['NObeyesdad'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2019, 'last_updated': 'Tue Sep 10 2024', 'dataset_doi': '10.24432/C5H31Z', 'creators': [], 'intro_paper': {'ID': 358, 'type': 'NATIVE', 'title': 'Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico', 'authors': 'Fabio Mendoza Palechor, Alexis De la Hoz Manotas', 'venue': 'Data in Brief', 'year': 2019, 'journal': None, 'DOI': '10.1016/j.dib.2019.104344', 'URL': 'https://www.semanticscholar.org/paper/35b40bacd2ffa9370885b7a3004d88995fd1d011', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Read the article (https://doi.org/10.1016/j.dib.2019.104344) to see the description of the attributes.', 'citation': None}}\n",
      "                              name     role         type demographic  \\\n",
      "0                           Gender  Feature  Categorical      Gender   \n",
      "1                              Age  Feature   Continuous         Age   \n",
      "2                           Height  Feature   Continuous        None   \n",
      "3                           Weight  Feature   Continuous        None   \n",
      "4   family_history_with_overweight  Feature       Binary        None   \n",
      "5                             FAVC  Feature       Binary        None   \n",
      "6                             FCVC  Feature      Integer        None   \n",
      "7                              NCP  Feature   Continuous        None   \n",
      "8                             CAEC  Feature  Categorical        None   \n",
      "9                            SMOKE  Feature       Binary        None   \n",
      "10                            CH2O  Feature   Continuous        None   \n",
      "11                             SCC  Feature       Binary        None   \n",
      "12                             FAF  Feature   Continuous        None   \n",
      "13                             TUE  Feature      Integer        None   \n",
      "14                            CALC  Feature  Categorical        None   \n",
      "15                          MTRANS  Feature  Categorical        None   \n",
      "16                      NObeyesdad   Target  Categorical        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                None  None             no  \n",
      "1                                                None  None             no  \n",
      "2                                                None  None             no  \n",
      "3                                                None  None             no  \n",
      "4   Has a family member suffered or suffers from o...  None             no  \n",
      "5            Do you eat high caloric food frequently?  None             no  \n",
      "6        Do you usually eat vegetables in your meals?  None             no  \n",
      "7              How many main meals do you have daily?  None             no  \n",
      "8                  Do you eat any food between meals?  None             no  \n",
      "9                                       Do you smoke?  None             no  \n",
      "10                 How much water do you drink daily?  None             no  \n",
      "11         Do you monitor the calories you eat daily?  None             no  \n",
      "12           How often do you have physical activity?  None             no  \n",
      "13  How much time do you use technological devices...  None             no  \n",
      "14                    How often do you drink alcohol?  None             no  \n",
      "15           Which transportation do you usually use?  None             no  \n",
      "16                                      Obesity level  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition = fetch_ucirepo(id=544) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.features \n",
    "y = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.targets.copy() \n",
    "  \n",
    "# metadata \n",
    "print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC','CALC','MTRANS']\n",
    "# One-hot encode categorical features, dropping the first category\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "X_encoded = X_encoded.astype({col: int for col in X_encoded.select_dtypes('bool').columns})\n",
    "\n",
    "# Convert X_encoded to a PyTorch tensor\n",
    "X_tensor = torch.tensor(X_encoded.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['NObeyesdad'] = y['NObeyesdad'].astype('category').cat.codes\n",
    "\n",
    "# Convert to tensor\n",
    "y_tensor = torch.tensor(y['NObeyesdad'].to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanFieldLayer(nn.Module):\n",
    "    \"\"\"Represents a mean-field Gaussian distribution over each layer of the network.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, init_var=1e-3):\n",
    "        super(MeanFieldLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Prior parameters p(theta)\n",
    "        self.w_mu_p = torch.zeros(input_dim, output_dim)\n",
    "        self.w_log_var_p = torch.zeros(input_dim, output_dim)\n",
    "        self.b_mu_p = torch.zeros(output_dim)\n",
    "        self.b_log_var_p = torch.zeros(output_dim)\n",
    "\n",
    "        # Variational parameters q(theta)\n",
    "        self.w_mu_q = nn.Parameter(torch.zeros(input_dim, output_dim), requires_grad=True)\n",
    "        self.w_log_var_q = nn.Parameter(\n",
    "            torch.ones(input_dim, output_dim) * torch.log(torch.tensor(init_var)), requires_grad=True\n",
    "        )  \n",
    "        self.b_mu_q = nn.Parameter(torch.zeros(output_dim), requires_grad=True)\n",
    "        self.b_log_var_q = nn.Parameter(\n",
    "            torch.ones(output_dim) * torch.log(torch.tensor(init_var)), requires_grad=True\n",
    "        )\n",
    "\n",
    "    # the priors do not change so could be stored as attributes, but\n",
    "    # it feels cleaner to access them in the same way as the posteriors\n",
    "    def p_w(self):\n",
    "        \"\"\"weight prior distribution\"\"\"\n",
    "        return torch.distributions.Normal(self.w_mu_p, (0.5 * self.w_log_var_p).exp())\n",
    "\n",
    "    def p_b(self):\n",
    "        \"\"\"bias prior distribution\"\"\"\n",
    "        return torch.distributions.Normal(self.b_mu_p, (0.5 * self.b_log_var_p).exp())\n",
    "\n",
    "    def q_w(self):\n",
    "        \"\"\"variational weight posterior\"\"\"\n",
    "        return torch.distributions.Normal(self.w_mu_q, (0.5 * self.w_log_var_q).exp())\n",
    "\n",
    "    def q_b(self):\n",
    "        \"\"\"variational bias posterior\"\"\"\n",
    "        return torch.distributions.Normal(self.b_mu_q, (0.5 * self.b_log_var_q).exp())\n",
    "\n",
    "    def kl(self):\n",
    "        weight_kl = torch.distributions.kl.kl_divergence(self.q_w(), self.p_w()).sum() \n",
    "        bias_kl = torch.distributions.kl.kl_divergence(self.q_b(), self.p_b()).sum()\n",
    "        return weight_kl + bias_kl\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Propagates x through this layer by sampling weights from the posterior\"\"\"\n",
    "        assert (len(x.shape) == 3), \"x should be shape (num_samples, batch_size, input_dim).\"\n",
    "        assert x.shape[-1] == self.input_dim\n",
    "\n",
    "        num_samples = x.shape[0]\n",
    "        # rsample carries out reparameterisation trick for us\n",
    "        weights = self.q_w().rsample((num_samples,))  # (num_samples, input_dim, output_dim).\n",
    "        biases = self.q_b().rsample((num_samples,)).unsqueeze(1)  # (num_samples, batch_size, output_dim)\n",
    "        return x @ weights + biases # (num_samples, batch_size, output_dim).\n",
    "\n",
    "\n",
    "\n",
    "class MeanFieldBNN(nn.Module):\n",
    "    \"\"\"Mean-field variational inference BNN.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dims,\n",
    "        output_dim,\n",
    "        # activation=nn.LeakyReLU(negative_slope=0.01),\n",
    "        activation=nn.ReLU(),\n",
    "        noise_std=1.0,\n",
    "    ):\n",
    "        super(MeanFieldBNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        self.noise_covar = torch.eye(output_dim)*noise_std\n",
    "\n",
    "        self.network = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims) + 1):\n",
    "            if i == 0:\n",
    "                self.network.append(MeanFieldLayer(self.input_dim, self.hidden_dims[i]))\n",
    "                self.network.append(self.activation)\n",
    "            elif i == len(hidden_dims):\n",
    "                self.network.append(\n",
    "                    MeanFieldLayer(self.hidden_dims[i - 1], self.output_dim)\n",
    "                )\n",
    "                self.network.append(torch.nn.Softmax(dim=1))\n",
    "\n",
    "            else:\n",
    "                self.network.append(\n",
    "                    MeanFieldLayer(self.hidden_dims[i - 1], self.hidden_dims[i])\n",
    "                )\n",
    "                self.network.append(self.activation) \n",
    "\n",
    "    def forward(self, x, num_samples=1):\n",
    "        \"\"\"Propagate the inputs through the network using num_samples weights.\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Inputs to the network.\n",
    "            num_samples (int, optional): Number of samples to use. Defaults to 1.\n",
    "        \"\"\"\n",
    "        assert len(x.shape) == 2, \"x.shape must be (batch_size, input_dim).\"\n",
    "\n",
    "        # Expand dimensions of x to (num_samples, batch_size, input_dim).\n",
    "        x = torch.unsqueeze(x, 0).repeat(num_samples, 1, 1)\n",
    "\n",
    "        # Propagate x through network\n",
    "        for layer in self.network:\n",
    "            x = layer(x)\n",
    "            \n",
    "                \n",
    "        assert len(x.shape) == 3, \"x.shape must be (num_samples, batch_size, output_dim)\"\n",
    "        assert x.shape[-1] == self.output_dim\n",
    "        return x\n",
    "        # return x.squeeze(-1)\n",
    "\n",
    "    def ll(self, y_obs, y_pred, num_samples=1):\n",
    "        # \"\"\"Computes the log likelihood of the outputs of self.forward(x) using a Bernoulli likelihood.\"\"\"\n",
    "        # print(y_pred.shape)\n",
    "        # y_pred = y_pred.squeeze(0).squeeze(-1)\n",
    "        # bernoulli = torch.distributions.Bernoulli(probs=y_pred)\n",
    "        # ll_tensor = bernoulli.log_prob(y_obs).mean(0) \n",
    "        # return ll_tensor.squeeze()\n",
    "        \"\"\"Computes the log likelihood of the outputs of self.forward(x)\"\"\"\n",
    "\n",
    "        ll_tensor = torch.tensor(0)\n",
    "        for i, y in enumerate(y_pred.squeeze(0)):\n",
    "            l = torch.distributions.Bernoulli(probs = y)\n",
    "            ll_tensor = ll_tensor + l.log_prob(y_obs[i].repeat(num_samples,1,1)).mean(0)\n",
    "        return ll_tensor.squeeze()\n",
    "\n",
    "\n",
    "    def kl(self):\n",
    "        \"\"\"Computes the KL divergence between the approximate posterior and the prior for the network.\"\"\"\n",
    "        return sum([layer.kl() for layer in self.network if isinstance(layer, MeanFieldLayer)])\n",
    "\n",
    "    def loss(self, x, y, num_samples=1):\n",
    "        \"\"\"Computes the ELBO and returns its negative\"\"\"\n",
    "\n",
    "        y_pred = self.forward(x, num_samples=num_samples)\n",
    "        exp_ll = self.ll(y, y_pred, num_samples=num_samples)\n",
    "        kl = self.kl()\n",
    "        return kl - exp_ll, exp_ll, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_model = MeanFieldBNN(23, [15, 15], 7, noise_std=0.5)\n",
    "# find value of noise_std that works best by trial and error, but this is of course\n",
    "# inherently a bit contrived since we know we set input noise std to 0.15 in dataset generation\n",
    "print(bnn_model)\n",
    "\n",
    "opt = torch.optim.Adam(\n",
    "    bnn_model.parameters(),\n",
    "    lr = 1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
