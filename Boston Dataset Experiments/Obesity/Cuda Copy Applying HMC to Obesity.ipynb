{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Using GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Using GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 544, 'name': 'Estimation of Obesity Levels Based On Eating Habits and Physical Condition ', 'repository_url': 'https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition', 'data_url': 'https://archive.ics.uci.edu/static/public/544/data.csv', 'abstract': 'This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. ', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Regression', 'Clustering'], 'characteristics': ['Multivariate'], 'num_instances': 2111, 'num_features': 16, 'feature_types': ['Integer'], 'demographics': ['Gender', 'Age'], 'target_col': ['NObeyesdad'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2019, 'last_updated': 'Tue Sep 10 2024', 'dataset_doi': '10.24432/C5H31Z', 'creators': [], 'intro_paper': {'ID': 358, 'type': 'NATIVE', 'title': 'Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico', 'authors': 'Fabio Mendoza Palechor, Alexis De la Hoz Manotas', 'venue': 'Data in Brief', 'year': 2019, 'journal': None, 'DOI': '10.1016/j.dib.2019.104344', 'URL': 'https://www.semanticscholar.org/paper/35b40bacd2ffa9370885b7a3004d88995fd1d011', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Read the article (https://doi.org/10.1016/j.dib.2019.104344) to see the description of the attributes.', 'citation': None}}\n",
      "                              name     role         type demographic  \\\n",
      "0                           Gender  Feature  Categorical      Gender   \n",
      "1                              Age  Feature   Continuous         Age   \n",
      "2                           Height  Feature   Continuous        None   \n",
      "3                           Weight  Feature   Continuous        None   \n",
      "4   family_history_with_overweight  Feature       Binary        None   \n",
      "5                             FAVC  Feature       Binary        None   \n",
      "6                             FCVC  Feature      Integer        None   \n",
      "7                              NCP  Feature   Continuous        None   \n",
      "8                             CAEC  Feature  Categorical        None   \n",
      "9                            SMOKE  Feature       Binary        None   \n",
      "10                            CH2O  Feature   Continuous        None   \n",
      "11                             SCC  Feature       Binary        None   \n",
      "12                             FAF  Feature   Continuous        None   \n",
      "13                             TUE  Feature      Integer        None   \n",
      "14                            CALC  Feature  Categorical        None   \n",
      "15                          MTRANS  Feature  Categorical        None   \n",
      "16                      NObeyesdad   Target  Categorical        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                None  None             no  \n",
      "1                                                None  None             no  \n",
      "2                                                None  None             no  \n",
      "3                                                None  None             no  \n",
      "4   Has a family member suffered or suffers from o...  None             no  \n",
      "5            Do you eat high caloric food frequently?  None             no  \n",
      "6        Do you usually eat vegetables in your meals?  None             no  \n",
      "7              How many main meals do you have daily?  None             no  \n",
      "8                  Do you eat any food between meals?  None             no  \n",
      "9                                       Do you smoke?  None             no  \n",
      "10                 How much water do you drink daily?  None             no  \n",
      "11         Do you monitor the calories you eat daily?  None             no  \n",
      "12           How often do you have physical activity?  None             no  \n",
      "13  How much time do you use technological devices...  None             no  \n",
      "14                    How often do you drink alcohol?  None             no  \n",
      "15           Which transportation do you usually use?  None             no  \n",
      "16                                      Obesity level  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition = fetch_ucirepo(id=544) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.features \n",
    "y = estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.data.targets.copy() \n",
    "  \n",
    "# metadata \n",
    "print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(estimation_of_obesity_levels_based_on_eating_habits_and_physical_condition.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "import torch.nn as nn\n",
    "\n",
    "from pyro.infer import MCMC, NUTS\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC','CALC','MTRANS']\n",
    "# One-hot encode categorical features, dropping the first category\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "X_encoded = X_encoded.astype({col: int for col in X_encoded.select_dtypes('bool').columns})\n",
    "\n",
    "# Convert X_encoded to a PyTorch tensor\n",
    "X_tensor = torch.tensor(X_encoded.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['NObeyesdad'] = y['NObeyesdad'].astype('category').cat.codes\n",
    "\n",
    "# Convert to tensor\n",
    "y_tensor = torch.tensor(y['NObeyesdad'].to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(X_tensor, y_tensor, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "    def __init__(self, in_dim=1, out_dim=1, hid_dim=10, n_hid_layers=2, prior_scale=5., device = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.device = device\n",
    "        self.activation = nn.ReLU()  # could also be ReLU or LeakyReLU\n",
    "        assert in_dim > 0 and out_dim > 0 and hid_dim > 0 and n_hid_layers > 0  # make sure the dimensions are valid\n",
    "\n",
    "        # Define the layer sizes and the PyroModule layer list\n",
    "        self.layer_sizes = [in_dim] + n_hid_layers * [hid_dim] + [out_dim]\n",
    "        layer_list = [PyroModule[nn.Linear](self.layer_sizes[idx - 1], self.layer_sizes[idx]) for idx in\n",
    "                      range(1, len(self.layer_sizes))]\n",
    "        self.layers = PyroModule[torch.nn.ModuleList](layer_list)#.to(self.device)\n",
    "\n",
    "        for layer_idx, layer in enumerate(self.layers):\n",
    "            layer.weight = PyroSample(dist.Normal(0., torch.tensor(prior_scale * np.sqrt(2 / self.layer_sizes[layer_idx]), dtype=torch.float, device = device)).expand(\n",
    "                [self.layer_sizes[layer_idx + 1], self.layer_sizes[layer_idx]]).to_event(2))\n",
    "            layer.bias = PyroSample(dist.Normal(0., torch.tensor(prior_scale, dtype=torch.float, device=device)).expand([self.layer_sizes[layer_idx + 1]]).to_event(1))\n",
    "\n",
    "        # for layer in self.layers:\n",
    "        #     layer.weight = layer.weight.to(self.device)  # Move weight tensor\n",
    "        #     layer.bias = layer.bias.to(self.device)  # Move bias tenso\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        x = x.to(device)\n",
    "        x = x.reshape(-1, self.in_dim)\n",
    "\n",
    "        x = self.activation(self.layers[0](x))  # input --> hidden\n",
    "        for layer in self.layers[1:-1]:\n",
    "            x = self.activation(layer(x))  # hidden --> hidden\n",
    "        x = self.layers[-1](x).squeeze()  # hidden --> output\n",
    "        x = torch.softmax(x, dim=1) # softmax activation\n",
    "        y = y.to(device)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Categorical(x), obs=y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hamiltonian Monte Carlo (HMC) kernel\n",
    "# NUTS = \"No-U-Turn Sampler\" (https://arxiv.org/abs/1111.4246), gives HMC an adaptive step size\n",
    "#in_dim=1, out_dim=1, hid_dim=10, n_hid_layers=5, prior_scale=5.\n",
    "x_tr, y_tr = x_tr.to(device), y_tr.to(device)\n",
    "x_te, y_te = x_te.to(device), y_te.to(device)\n",
    "model = BNN(in_dim=x_tr.shape[1], out_dim=7, hid_dim=10, n_hid_layers=2, prior_scale=5., device = device)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/750 [00:00, ?it/s]c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyro\\poutine\\subsample_messenger.py:70: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  result = torch.tensor(0.0, device=self.device)\n",
      "Sample: 100%|██████████| 750/750 [1:58:57,  9.52s/it, step size=2.93e-04, acc. prob=0.961]\n"
     ]
    }
   ],
   "source": [
    "# define model and data\n",
    "\n",
    "# define MCMC sampler\n",
    "nuts_kernel = NUTS(model, jit_compile=True)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=250, warmup_steps=500)\n",
    "mcmc.run(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layers.0.bias', 'layers.0.weight', 'layers.1.bias', 'layers.1.weight', 'layers.2.bias', 'layers.2.weight']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([250, 10, 23])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_samples = mcmc.get_samples()\n",
    "\n",
    "keys = list(post_samples.keys())\n",
    "print(keys)\n",
    "\n",
    "post_samples[keys[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save dictionary to a pickle file\n",
    "with open('post_samples.pkl', 'wb') as f:\n",
    "    pickle.dump(post_samples, f)\n",
    "\n",
    "# Load dictionary from the pickle file\n",
    "with open('post_samples.pkl', 'rb') as f:\n",
    "    loaded_samples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers.0.bias': tensor([[-0.1837, -1.1126, -0.5612,  ..., -0.2912,  1.3319,  5.4971],\n",
       "         [-0.0365, -1.0210, -0.5311,  ..., -0.3331,  1.3475,  5.5114],\n",
       "         [-0.0238, -1.0140, -0.5473,  ..., -0.3932,  1.3438,  5.4972],\n",
       "         ...,\n",
       "         [ 0.5947, -1.2018, -0.6721,  ..., -0.9122,  0.9699,  4.6841],\n",
       "         [ 0.4834, -1.1944, -0.6413,  ..., -1.0111,  0.9822,  4.6518],\n",
       "         [ 0.5320, -1.1777, -0.6394,  ..., -0.9437,  0.9775,  4.6194]],\n",
       "        device='cuda:0'),\n",
       " 'layers.0.weight': tensor([[[-1.6514e+00, -1.1698e+00,  5.2780e-01,  ...,  2.2376e-01,\n",
       "           -3.0341e+00,  2.2060e+00],\n",
       "          [ 1.8739e+00,  1.4889e-02, -2.1047e+00,  ...,  1.2718e+00,\n",
       "            7.8635e-01, -9.6376e-01],\n",
       "          [ 6.5406e-01,  1.1728e+00,  2.9917e+00,  ..., -3.7824e-01,\n",
       "            2.0104e+00,  3.1188e+00],\n",
       "          ...,\n",
       "          [ 2.8865e+00,  5.0704e-01, -1.8589e+00,  ..., -1.2812e+00,\n",
       "           -2.3845e-02,  1.4113e+00],\n",
       "          [-2.2488e+00, -5.7536e-01, -8.5153e-01,  ...,  1.8617e-02,\n",
       "           -1.2727e+00,  5.8083e-01],\n",
       "          [-3.1328e-02, -1.6386e+00, -6.1828e-01,  ...,  1.8305e+00,\n",
       "           -3.6497e-01, -1.4675e+00]],\n",
       " \n",
       "         [[-1.6876e+00, -1.2347e+00,  5.3564e-01,  ...,  4.3497e-01,\n",
       "           -3.0180e+00,  2.3806e+00],\n",
       "          [ 1.9105e+00,  7.6250e-02, -2.1019e+00,  ...,  1.2648e+00,\n",
       "            8.7704e-01, -8.5098e-01],\n",
       "          [ 6.5860e-01,  1.1031e+00,  3.0266e+00,  ..., -3.9100e-01,\n",
       "            1.9965e+00,  3.1921e+00],\n",
       "          ...,\n",
       "          [ 2.9108e+00,  4.9404e-01, -1.8488e+00,  ..., -1.2207e+00,\n",
       "           -1.1305e-01,  1.4312e+00],\n",
       "          [-2.2775e+00, -5.6831e-01, -8.5905e-01,  ...,  1.4440e-01,\n",
       "           -1.2706e+00,  5.6184e-01],\n",
       "          [-3.5697e-02, -1.6607e+00, -6.2994e-01,  ...,  2.0475e+00,\n",
       "           -3.3536e-01, -1.4547e+00]],\n",
       " \n",
       "         [[-1.6818e+00, -1.2521e+00,  5.3923e-01,  ...,  5.1413e-01,\n",
       "           -3.0369e+00,  2.4321e+00],\n",
       "          [ 1.9827e+00, -8.8547e-04, -2.0876e+00,  ...,  1.2391e+00,\n",
       "            8.3007e-01, -8.3036e-01],\n",
       "          [ 6.5144e-01,  1.0881e+00,  2.9994e+00,  ..., -3.5339e-01,\n",
       "            2.0125e+00,  3.1052e+00],\n",
       "          ...,\n",
       "          [ 2.9231e+00,  5.0622e-01, -1.8075e+00,  ..., -1.2388e+00,\n",
       "           -1.8663e-01,  1.4124e+00],\n",
       "          [-2.2870e+00, -5.8826e-01, -8.4516e-01,  ...,  2.3426e-01,\n",
       "           -1.2623e+00,  6.7145e-01],\n",
       "          [-4.0048e-02, -1.6871e+00, -6.2892e-01,  ...,  2.0753e+00,\n",
       "           -3.5870e-01, -1.4246e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.4652e+00, -2.0884e+00,  4.4432e-01,  ...,  2.3037e-01,\n",
       "           -3.3707e+00,  2.6273e+00],\n",
       "          [ 1.4938e+00,  9.0635e-01, -2.0319e+00,  ...,  9.3724e-01,\n",
       "            1.3198e+00, -9.8692e-01],\n",
       "          [ 9.0020e-01,  1.9186e+00,  2.7330e+00,  ..., -1.2140e-01,\n",
       "            1.4777e+00,  3.0158e+00],\n",
       "          ...,\n",
       "          [ 1.9646e+00,  3.9788e-01, -1.5364e+00,  ..., -1.8902e+00,\n",
       "           -5.1545e-01, -3.9430e-01],\n",
       "          [-2.3430e+00, -9.0598e-01, -5.7848e-01,  ...,  7.3656e-01,\n",
       "           -1.5427e+00,  3.9436e-01],\n",
       "          [-6.5598e-02, -1.3848e+00, -7.7491e-01,  ...,  1.2610e+00,\n",
       "           -7.3429e-01, -1.4332e+00]],\n",
       " \n",
       "         [[-1.4768e+00, -2.0237e+00,  4.4845e-01,  ...,  3.2819e-01,\n",
       "           -3.3886e+00,  2.6131e+00],\n",
       "          [ 1.4735e+00,  9.2327e-01, -2.0208e+00,  ...,  9.3065e-01,\n",
       "            1.3360e+00, -9.1723e-01],\n",
       "          [ 9.1497e-01,  1.8776e+00,  2.6796e+00,  ..., -1.5058e-01,\n",
       "            1.4882e+00,  3.0316e+00],\n",
       "          ...,\n",
       "          [ 1.8173e+00,  3.9127e-01, -1.5619e+00,  ..., -1.8985e+00,\n",
       "           -4.5119e-01, -3.8072e-01],\n",
       "          [-2.3070e+00, -9.2731e-01, -5.7844e-01,  ...,  7.7453e-01,\n",
       "           -1.5440e+00,  4.1049e-01],\n",
       "          [-7.3055e-02, -1.3950e+00, -7.4425e-01,  ...,  1.1661e+00,\n",
       "           -7.6492e-01, -1.4602e+00]],\n",
       " \n",
       "         [[-1.4739e+00, -1.9923e+00,  4.5108e-01,  ...,  3.9326e-01,\n",
       "           -3.3962e+00,  2.6239e+00],\n",
       "          [ 1.4686e+00,  8.9843e-01, -2.0065e+00,  ...,  9.2928e-01,\n",
       "            1.3235e+00, -9.4879e-01],\n",
       "          [ 9.2427e-01,  1.9198e+00,  2.6785e+00,  ..., -1.5200e-01,\n",
       "            1.4760e+00,  3.0010e+00],\n",
       "          ...,\n",
       "          [ 1.7532e+00,  3.9643e-01, -1.5660e+00,  ..., -1.8860e+00,\n",
       "           -4.3898e-01, -4.5438e-01],\n",
       "          [-2.3004e+00, -9.2925e-01, -5.9036e-01,  ...,  7.4591e-01,\n",
       "           -1.5453e+00,  3.6039e-01],\n",
       "          [-7.4013e-02, -1.3975e+00, -7.4990e-01,  ...,  1.1992e+00,\n",
       "           -7.5145e-01, -1.4702e+00]]], device='cuda:0'),\n",
       " 'layers.1.bias': tensor([[-1.1061, -3.4531,  0.8092,  ...,  5.2856, -0.3057, -0.5240],\n",
       "         [-1.0586, -3.4976,  0.7952,  ...,  5.3141, -0.3239, -0.5277],\n",
       "         [-1.0537, -3.7098,  0.7517,  ...,  5.3277, -0.3092, -0.5123],\n",
       "         ...,\n",
       "         [-1.1516,  1.2427,  0.5244,  ...,  5.4509, -0.7066, -0.3876],\n",
       "         [-1.1301,  1.2502,  0.4844,  ...,  5.4626, -0.6938, -0.3950],\n",
       "         [-1.1090,  1.2122,  0.4811,  ...,  5.4772, -0.7035, -0.4138]],\n",
       "        device='cuda:0'),\n",
       " 'layers.1.weight': tensor([[[ 1.5479, -1.6471,  1.5981,  ..., -1.6610,  5.6619,  4.2420],\n",
       "          [ 2.2696, -2.2829, -0.6807,  ..., -3.7137,  1.4049, -1.2137],\n",
       "          [ 1.1591, -2.3416,  0.4534,  ...,  1.4587, -1.2457, -2.7718],\n",
       "          ...,\n",
       "          [-0.4807,  3.5631,  0.3950,  ...,  2.6762,  3.1942,  2.9898],\n",
       "          [-0.9149, -0.0183, -0.4703,  ...,  1.7195, -0.1050,  4.1097],\n",
       "          [-2.6198,  0.2228, -0.3712,  ...,  0.4374,  0.7544,  1.2724]],\n",
       " \n",
       "         [[ 1.5240, -1.6683,  1.6113,  ..., -1.6299,  5.6279,  4.2923],\n",
       "          [ 2.2604, -2.2676, -0.6505,  ..., -3.7468,  1.4129, -1.2497],\n",
       "          [ 1.1695, -2.3461,  0.5655,  ...,  1.4777, -1.2408, -2.7272],\n",
       "          ...,\n",
       "          [-0.4720,  3.5436,  0.3966,  ...,  2.7054,  3.1965,  2.9834],\n",
       "          [-0.9285, -0.0747, -0.4695,  ...,  1.5539, -0.1175,  4.1448],\n",
       "          [-2.6597,  0.2296, -0.4000,  ...,  1.2253,  0.7269,  1.1751]],\n",
       " \n",
       "         [[ 1.5308, -1.6725,  1.6381,  ..., -1.6720,  5.6129,  4.3241],\n",
       "          [ 2.2747, -2.2754, -0.6348,  ..., -3.6276,  1.3359, -1.2909],\n",
       "          [ 1.1452, -2.3329,  0.6103,  ...,  1.4757, -1.2651, -2.6039],\n",
       "          ...,\n",
       "          [-0.4787,  3.6135,  0.3908,  ...,  2.7383,  3.2058,  2.9856],\n",
       "          [-0.9231, -0.1517, -0.5092,  ...,  1.8716, -0.1097,  4.1422],\n",
       "          [-2.6550,  0.2585, -0.3614,  ...,  1.3949,  0.7091,  1.1680]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.5737, -1.8970,  1.3723,  ..., -1.5020,  5.5392,  3.4880],\n",
       "          [ 2.2406, -2.3541, -1.0656,  ..., -4.2433,  1.7303, -0.7693],\n",
       "          [ 1.6826, -2.0658, -0.8645,  ...,  1.5190, -1.1438, -3.5537],\n",
       "          ...,\n",
       "          [-0.6442,  3.0505,  0.3946,  ...,  2.6350,  3.3643,  3.0387],\n",
       "          [-0.7939,  0.5712, -0.9718,  ...,  0.1932, -0.4826,  4.3618],\n",
       "          [-2.7439,  0.0775, -0.1729,  ...,  1.7981,  0.9332,  0.3028]],\n",
       " \n",
       "         [[ 1.5718, -1.8947,  1.3331,  ..., -1.4911,  5.5395,  3.4496],\n",
       "          [ 2.2702, -2.3402, -1.1173,  ..., -4.2841,  1.7341, -0.7466],\n",
       "          [ 1.7077, -2.0841, -0.8414,  ...,  1.5176, -1.0972, -3.4225],\n",
       "          ...,\n",
       "          [-0.6368,  3.0780,  0.4031,  ...,  2.6395,  3.3313,  3.0531],\n",
       "          [-0.7891,  0.5597, -1.0348,  ..., -0.2127, -0.4762,  4.3921],\n",
       "          [-2.7677,  0.0865, -0.0994,  ...,  1.9468,  0.9408,  0.2938]],\n",
       " \n",
       "         [[ 1.5686, -1.8857,  1.3304,  ..., -1.4930,  5.5669,  3.4479],\n",
       "          [ 2.2678, -2.3486, -1.1275,  ..., -4.1968,  1.7022, -0.7556],\n",
       "          [ 1.7309, -2.1004, -0.8501,  ...,  1.5258, -1.1162, -3.4392],\n",
       "          ...,\n",
       "          [-0.6430,  3.0881,  0.3966,  ...,  2.6527,  3.3377,  3.0544],\n",
       "          [-0.7908,  0.5422, -1.0181,  ..., -0.2641, -0.4499,  4.3771],\n",
       "          [-2.7698,  0.0469, -0.1160,  ...,  1.9335,  0.9385,  0.3278]]],\n",
       "        device='cuda:0'),\n",
       " 'layers.2.bias': tensor([[-1.7048e-01, -1.9807e+00, -9.7155e-01,  ..., -7.6687e+00,\n",
       "           2.2194e+00,  3.8046e-01],\n",
       "         [-1.6943e-01, -1.9973e+00, -9.5408e-01,  ..., -7.5662e+00,\n",
       "           2.6603e+00,  3.9242e-01],\n",
       "         [-1.3251e-01, -1.9821e+00, -9.4499e-01,  ..., -7.6980e+00,\n",
       "           2.7208e+00,  3.9180e-01],\n",
       "         ...,\n",
       "         [-5.3456e-02, -2.1078e+00, -9.7659e-01,  ..., -4.9300e+00,\n",
       "           4.6744e-01,  3.2264e-01],\n",
       "         [-4.9789e-03, -2.0993e+00, -9.7959e-01,  ..., -4.9552e+00,\n",
       "           3.4185e-01,  3.0370e-01],\n",
       "         [ 5.3395e-03, -2.1083e+00, -9.8252e-01,  ..., -4.9065e+00,\n",
       "           3.0614e-01,  2.9274e-01]], device='cuda:0'),\n",
       " 'layers.2.weight': tensor([[[ 0.5641, -0.5324,  3.8145,  ..., -0.3907,  0.7527, -0.2727],\n",
       "          [-1.2241, -1.4561, -1.4498,  ...,  0.3641, -0.6441,  2.9904],\n",
       "          [-0.1696,  2.1459,  1.0950,  ...,  2.2838,  3.2370, -3.6188],\n",
       "          ...,\n",
       "          [-0.2781,  0.5063,  0.8297,  ..., -1.0259,  1.5695,  0.3682],\n",
       "          [-1.2574,  2.3018, -1.4571,  ..., -2.2757,  2.5078,  0.1987],\n",
       "          [ 4.7102, -1.7505,  2.6056,  ..., -3.6447, -0.4488, -1.6103]],\n",
       " \n",
       "         [[ 0.5901, -0.4392,  3.7997,  ..., -0.4046,  0.7861, -0.2704],\n",
       "          [-1.2046, -1.4789, -1.5725,  ...,  0.3622, -0.7232,  2.9931],\n",
       "          [-0.1750,  2.1684,  1.0614,  ...,  2.2923,  3.2079, -3.6048],\n",
       "          ...,\n",
       "          [-0.2700,  0.5434,  0.8177,  ..., -0.9922,  1.8352,  0.3583],\n",
       "          [-1.2635,  2.2869, -1.4271,  ..., -2.2826,  2.5266,  0.1849],\n",
       "          [ 4.7478, -1.7426,  2.5888,  ..., -3.6433, -0.4622, -1.5015]],\n",
       " \n",
       "         [[ 0.6356, -0.4113,  3.7839,  ..., -0.3666,  0.8915, -0.2468],\n",
       "          [-1.1950, -1.4689, -1.6445,  ...,  0.3020, -0.7121,  3.0125],\n",
       "          [-0.1992,  2.1674,  1.0784,  ...,  2.2982,  3.1643, -3.6011],\n",
       "          ...,\n",
       "          [-0.2721,  0.5044,  0.8452,  ..., -0.9454,  1.6559,  0.3343],\n",
       "          [-1.2544,  2.3731, -1.4519,  ..., -2.2800,  2.5053,  0.1513],\n",
       "          [ 4.7285, -1.7510,  2.5509,  ..., -3.6416, -0.4705, -1.5284]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 2.1930, -0.6128,  4.0165,  ...,  0.1127,  1.2682, -0.3381],\n",
       "          [-0.9589, -1.4690, -2.1571,  ...,  0.9142, -0.8863,  1.7302],\n",
       "          [-0.3001,  2.4205,  1.8904,  ...,  2.2040,  3.0958, -3.5223],\n",
       "          ...,\n",
       "          [-0.0935,  0.5096,  0.9152,  ..., -1.0031, -0.6624,  0.2288],\n",
       "          [-1.1170,  0.1989, -0.9473,  ..., -2.0610,  2.6461, -0.8165],\n",
       "          [ 4.7268, -1.7664,  2.5932,  ..., -3.5092, -0.5162, -2.8720]],\n",
       " \n",
       "         [[ 2.2074, -0.6137,  4.0274,  ...,  0.1227,  1.1952, -0.3544],\n",
       "          [-0.9084, -1.4838, -2.1925,  ...,  0.8998, -0.8837,  1.7174],\n",
       "          [-0.3136,  2.4060,  2.0203,  ...,  2.2117,  3.1198, -3.5069],\n",
       "          ...,\n",
       "          [-0.1263,  0.5379,  0.8730,  ..., -1.0120, -0.3750,  0.2339],\n",
       "          [-1.1352,  0.3680, -0.9556,  ..., -2.0546,  2.6694, -0.8725],\n",
       "          [ 4.6941, -1.7744,  2.6209,  ..., -3.5120, -0.5182, -2.8713]],\n",
       " \n",
       "         [[ 2.2267, -0.6088,  4.0204,  ...,  0.1089,  1.1853, -0.3625],\n",
       "          [-0.9108, -1.4650, -2.1756,  ...,  0.9112, -0.8874,  1.7048],\n",
       "          [-0.3194,  2.4030,  2.0227,  ...,  2.2154,  3.0859, -3.5134],\n",
       "          ...,\n",
       "          [-0.1212,  0.5378,  0.8751,  ..., -1.0254, -0.4583,  0.2348],\n",
       "          [-1.1367,  0.4129, -0.9534,  ..., -2.0607,  2.6694, -0.8700],\n",
       "          [ 4.7098, -1.7795,  2.5991,  ..., -3.5137, -0.5179, -2.9739]]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([634])) that is different to the input size (torch.Size([50, 634])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.1215)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictive = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "preds = predictive(x_te)['obs']\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "mse(preds, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 3,  ..., 2, 5, 2],\n",
       "        [0, 5, 5,  ..., 5, 1, 4],\n",
       "        [6, 3, 6,  ..., 5, 3, 6],\n",
       "        ...,\n",
       "        [4, 1, 0,  ..., 5, 0, 3],\n",
       "        [2, 3, 1,  ..., 6, 0, 2],\n",
       "        [2, 1, 3,  ..., 2, 4, 2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preds is 50x634\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0800, 0.0400, 0.1800,  ..., 0.1400, 0.1800, 0.0200],\n",
       "        [0.1000, 0.2600, 0.2000,  ..., 0.1600, 0.0600, 0.3000],\n",
       "        [0.1600, 0.0400, 0.1200,  ..., 0.2000, 0.1600, 0.1200],\n",
       "        ...,\n",
       "        [0.2000, 0.2200, 0.1600,  ..., 0.1400, 0.3000, 0.2800],\n",
       "        [0.1000, 0.0600, 0.0600,  ..., 0.1200, 0.1200, 0.0200],\n",
       "        [0.2600, 0.0000, 0.1000,  ..., 0.1400, 0.0600, 0.0200]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_frequencies = torch.zeros(7, 634)\n",
    "for j in range(preds.shape[1]):\n",
    "    # Count the occurrences of each label in column j\n",
    "    label_counts = torch.bincount(preds[:, j], minlength=7)\n",
    "    # Calculate the relative frequency by dividing by the total number of predictions (50)\n",
    "    relative_frequencies[:, j] = label_counts.float() / preds.shape[0]\n",
    "\n",
    "relative_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
